name: "dlib_face_descriptor"
backend: "python"
default_model_filename: "model.py"
max_batch_size: 16
dynamic_batching {
  preferred_batch_size: [ 1, 8, 16 ]
  max_queue_delay_microseconds: 50000
}

instance_group [
  {
      count: 4
      kind: KIND_GPU
  }
]




input [
{
    name: "face_clip"
    data_type: TYPE_UINT8
    format: FORMAT_NHWC
    dims: [ -1, -1, 3 ]
}
]

output [

    {
      name: "face_descriptor", 
      data_type: TYPE_FP32,
      dims: [ 128 ]
    }
]

parameters {
  key: "model_description"
  value: {
      string_value: "Given a face clip, calculate a 128D facial descriptor. Helpful as a feature extractor. Citation: C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic. 300 faces In-the-wild challenge: Database and results. Image and Vision Computing (IMAVIS), Special Issue on Facial Landmark Localisation 'In-The-Wild'. 2016. All models downloaded from https://github.com/davisking/dlib-models"
  }
}

parameters {
  key: "model_architecture"
  value: {
      string_value: "This is trained on the ibug 300-W dataset (https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/)"
  }
}

parameters {        
  key: "license"
  value: {
      string_value: "The license for this dataset excludes commercial use and Stefanos Zafeiriou, one of the creators of the dataset, asked me to include a note here saying that the trained model therefore can't be used in a commerical product. So you should contact a lawyer or talk to Imperial College London to find out if it's OK for you to use this model in a commercial product."
  }
}