{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6456e23-f975-4262-8389-29fe0b4de469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import DataNode\n",
    "import numpy as np\n",
    "from numpy import array, float32\n",
    "import os\n",
    "\n",
    "from utils import index_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7646e9-5b02-44d8-aecf-a85653aa3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/volume1/local_only/pictures\"\n",
    "max_batch_size = 16\n",
    "filenames = index_directory(image_dir, formats=(\".png\", \".jpeg\", \".jpg\"))\n",
    "seed = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3addc-d53e-4cad-a3d0-0440ba177368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "MODEL_VERSION = os.getenv(\"MODEL_VERSION\")\n",
    "TRITON_SERVER_URL = os.getenv(\"TRITON_SERVER_URL\")\n",
    "FACE_DETECT_MODEL_NAME = os.getenv(\"FACE_DETECT_MODEL_NAME\")\n",
    "\n",
    "triton_client = grpcclient.InferenceServerClient(url=TRITON_SERVER_URL, verbose=False)\n",
    "model_metadata = triton_client.get_model_metadata(\n",
    "    model_name=FACE_DETECT_MODEL_NAME, model_version=MODEL_VERSION\n",
    ")\n",
    "model_config = triton_client.get_model_config(\n",
    "    model_name=FACE_DETECT_MODEL_NAME, model_version=MODEL_VERSION\n",
    ").config\n",
    "input_names = [i.name for i in model_config.input]\n",
    "output_names = [i.name for i in model_config.output]\n",
    "\n",
    "\n",
    "@pipeline_def\n",
    "def client_pipeline(filenames):\n",
    "    raw_image_tensor, _ = fn.readers.file(files=filenames, random_shuffle=False)\n",
    "    return raw_image_tensor\n",
    "\n",
    "\n",
    "raw_image_tensor = client_pipeline(filenames, num_threads=4, batch_size=32, device_id=0)\n",
    "raw_image_tensor.build()\n",
    "(raw_image_tensor,) = raw_image_tensor.run()\n",
    "input_image_data_list = [np.expand_dims(np.array(i), axis=0) for i in raw_image_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7f578-0074-4558-ad37-0edb8108ac67",
   "metadata": {},
   "source": [
    "```python\n",
    "class FacenetPipeline:\n",
    "    def __init__(self, raw_image_tensor):\n",
    "        self.raw_image_tensor = raw_image_tensor\n",
    "        self.one_over_255 = 1 / 255.0\n",
    "        self.shapes = fn.peek_image_shape(self.raw_image_tensor)\n",
    "\n",
    "    def load_images(self):\n",
    "        self.image_tensor = fn.decoders.image(\n",
    "            self.raw_image_tensor, output_type=types.GRAY, device=\"mixed\"\n",
    "        )\n",
    "\n",
    "    def color_space_conversion(self):\n",
    "        self.image_tensor = fn.color_space_conversion(\n",
    "            self.image_tensor, image_type=types.GRAY, output_type=types.RGB\n",
    "        )\n",
    "        self.image_tensor = fn.brightness_contrast(self.image_tensor)\n",
    "\n",
    "    def maybe_rotate(self):\n",
    "        if_rotate = self.shapes[0] > self.shapes[1]\n",
    "        angle = 90.0 * if_rotate\n",
    "        self.image_tensor = fn.rotate(self.image_tensor, angle=angle)\n",
    "\n",
    "    def resize_images(self):\n",
    "        self.image_tensor = fn.resize(\n",
    "            self.image_tensor,\n",
    "            resize_longer=736,\n",
    "            interp_type=types.DALIInterpType.INTERP_LANCZOS3,\n",
    "        )\n",
    "        self.image_tensor = fn.crop(\n",
    "            self.image_tensor,\n",
    "            crop_w=736,\n",
    "            crop_h=416,\n",
    "            crop_pos_x=0.5,\n",
    "            crop_pos_y=0.5,\n",
    "            out_of_bounds_policy=\"pad\",\n",
    "        )\n",
    "\n",
    "    @pipeline_def\n",
    "    def facenet_reshape(self):\n",
    "        self.load_images()\n",
    "        self.color_space_conversion()\n",
    "        self.maybe_rotate()\n",
    "        self.resize_images()\n",
    "        self.image_tensor = (\n",
    "            fn.transpose(self.image_tensor, perm=[2, 0, 1]) * self.one_over_255\n",
    "        )\n",
    "\n",
    "        return self.image_tensor, self.shapes\n",
    "\n",
    "\n",
    "facenet_pipeline = FacenetPipeline(raw_image_tensor)\n",
    "facenet_pipeline = facenet_pipeline.facenet_reshape(\n",
    "    batch_size=max_batch_size, num_threads=4, device_id=0, seed=seed\n",
    ")\n",
    "facenet_pipeline.build()\n",
    "raw_image_tensors, shapes = facenet_pipeline.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ff778-3133-48b7-a713-2b8fd83e1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for input_image_data in input_image_data_list:\n",
    "\n",
    "    inputs = [grpcclient.InferInput(input_names[0], input_image_data.shape, \"UINT8\")]\n",
    "    inputs[0].set_data_from_numpy(input_image_data)\n",
    "\n",
    "    outputs = [\n",
    "        grpcclient.InferRequestedOutput(output_name, class_count=0)\n",
    "        for output_name in output_names\n",
    "    ]\n",
    "    response = triton_client.infer(FACE_DETECT_MODEL_NAME, inputs, outputs=outputs)\n",
    "\n",
    "    results.append(response.as_numpy(\"true_boxes\"))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a22c6-3f4c-4d5c-9a90-1b74b774727d",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def show_images(image_batch, channels_first=True):\n",
    "    columns = 4\n",
    "    rows = (max_batch_size + 1) // (columns)\n",
    "    fig = plt.figure(figsize=(32, (32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(\n",
    "            gs[j], title=\"{} face(s)\".format(len(eval(results[j].decode(\"utf-8\"))))\n",
    "        )\n",
    "        plt.axis(\"off\")\n",
    "        if channels_first:\n",
    "            image = np.transpose(image_batch.at(j), [1, 2, 0])\n",
    "        else:\n",
    "            image = image_batch.at(j)\n",
    "        plt.imshow(image)\n",
    "\n",
    "\n",
    "show_images(raw_image_tensors.as_cpu())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a648b8d-7574-4818-bb27-f110b35097a6",
   "metadata": {},
   "source": [
    "```python\n",
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.triton import autoserialize\n",
    "\n",
    "\n",
    "class FacenetPipeline:\n",
    "    def __init__(self):\n",
    "        self.raw_image_tensor = fn.external_source(name=\"input_image_data\")\n",
    "        self.one_over_255 = 1 / 255.0\n",
    "        self.shapes = fn.peek_image_shape(self.raw_image_tensor)\n",
    "\n",
    "    def load_images(self):\n",
    "        self.image_tensor = fn.decoders.image(\n",
    "            self.raw_image_tensor, output_type=types.GRAY, device=\"mixed\"\n",
    "        )\n",
    "\n",
    "    def color_space_conversion(self):\n",
    "        self.image_tensor = fn.color_space_conversion(\n",
    "            self.image_tensor, image_type=types.GRAY, output_type=types.RGB\n",
    "        )\n",
    "        self.image_tensor = fn.brightness_contrast(self.image_tensor)\n",
    "\n",
    "    def maybe_rotate(self):\n",
    "        if_rotate = self.shapes[0] > self.shapes[1]\n",
    "        angle = 90.0 * if_rotate\n",
    "        self.image_tensor = fn.rotate(self.image_tensor, angle=angle)\n",
    "\n",
    "    def resize_images(self):\n",
    "        self.image_tensor = fn.resize(\n",
    "            self.image_tensor,\n",
    "            resize_longer=736,\n",
    "            interp_type=types.DALIInterpType.INTERP_LANCZOS3,\n",
    "        )\n",
    "        self.image_tensor = fn.crop(\n",
    "            self.image_tensor,\n",
    "            crop_w=736,\n",
    "            crop_h=416,\n",
    "            crop_pos_x=0.5,\n",
    "            crop_pos_y=0.5,\n",
    "            out_of_bounds_policy=\"pad\",\n",
    "        )\n",
    "\n",
    "    @autoserialize\n",
    "    @pipeline_def(batch_size=32, num_threads=4, device_id=0)\n",
    "    def facenet_reshape(self):\n",
    "        self.load_images()\n",
    "        self.color_space_conversion()\n",
    "        self.maybe_rotate()\n",
    "        self.resize_images()\n",
    "        self.image_tensor = (\n",
    "            fn.transpose(self.image_tensor, perm=[2, 0, 1]) * self.one_over_255\n",
    "        )\n",
    "\n",
    "        return self.image_tensor, self.shapes\n",
    "\n",
    "\n",
    "facenet_pipeline = FacenetPipeline()\n",
    "_ = facenet_pipeline.facenet_reshape().serialize(filename=\"model.dali\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65786c84-449f-497c-a7f1-f13a154ca511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
