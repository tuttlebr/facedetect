{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9533e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "import json\n",
    "import dlib\n",
    "from PIL import Image, ImageDraw\n",
    "from pillow_heif import register_heif_opener\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED, as_completed\n",
    "\n",
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dlib_face_descriptor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_to_triton(image_data, image_wise_bboxes, request_id=\"\"):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    image_wise_bboxes = np.array(\n",
    "        [float(eval(i)) for i in image_wise_bboxes], dtype=\"float32\"\n",
    "    ).reshape((1, 4))\n",
    "\n",
    "    inputs.append(grpcclient.InferInput(\"raw_image_array\", image_data.shape, \"UINT8\"))\n",
    "    inputs.append(grpcclient.InferInput(\"bboxes\", [1, 4], \"FP32\"))\n",
    "\n",
    "    inputs[0].set_data_from_numpy(image_data)\n",
    "    inputs[1].set_data_from_numpy(image_wise_bboxes)\n",
    "\n",
    "    outputs = [grpcclient.InferRequestedOutput(\"face_descriptor\")]\n",
    "\n",
    "    return triton_client.infer(\n",
    "        model_name, inputs, outputs=outputs, request_id=request_id\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_model_grpc(model_metadata, model_config):\n",
    "    \"\"\"\n",
    "    Check the configuration of a model to make sure it meets the\n",
    "    requirements for an image classification network (as expected by\n",
    "    this client)\n",
    "    \"\"\"\n",
    "    if len(model_metadata.inputs) != 2:\n",
    "        raise Exception(\"expecting 2 input, got {}\".format(len(model_metadata.inputs)))\n",
    "\n",
    "    if len(model_config.input) != 2:\n",
    "        raise Exception(\n",
    "            \"expecting 2 input in model configuration, got {}\".format(\n",
    "                len(model_config.input)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    input_metadata = model_metadata.inputs\n",
    "    output_metadata = model_metadata.outputs\n",
    "\n",
    "    return (input_metadata, output_metadata, model_config.max_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0362a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client = grpcclient.InferenceServerClient(url=url, verbose=False)\n",
    "\n",
    "model_metadata = triton_client.get_model_metadata(\n",
    "    model_name=model_name, model_version=model_version\n",
    ")\n",
    "\n",
    "model_config = triton_client.get_model_config(\n",
    "    model_name=model_name, model_version=model_version\n",
    ").config\n",
    "\n",
    "input_metadata, output_metadata, max_batch_size = parse_model_grpc(\n",
    "    model_metadata, model_config\n",
    ")\n",
    "\n",
    "max_workers = max_batch_size * model_config.instance_group[0].count\n",
    "input_names = [i.name for i in input_metadata]\n",
    "output_names = [i.name for i in output_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(facedetect_data_filename) as f:\n",
    "    facedetect_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c314e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(facedetect_data))\n",
    "futures = []\n",
    "ids = []\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    for chunk in chunked(facedetect_data, 1000):\n",
    "        futures = []\n",
    "        for items in chunk:\n",
    "            pbar.update()\n",
    "            if items[\"faces\"][0][\"probability\"] != \"0\":\n",
    "                image = load_image(items[\"filename\"])\n",
    "                for idx, face in enumerate(items[\"faces\"]):\n",
    "                    request_id = \"{}-{}\".format(items[\"filename\"], idx)\n",
    "                    image_wise_bboxes = tuple(face[\"bbox\"].values())\n",
    "                    futures.append(\n",
    "                        executor.submit(\n",
    "                            submit_to_triton,\n",
    "                            image,\n",
    "                            image_wise_bboxes,\n",
    "                            request_id=request_id,\n",
    "                        )\n",
    "                    )\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            ids.append(result.get_response().id)\n",
    "            results.append(dlib.vector(result.as_numpy(output_names[0]).squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# for idx, row in tqdm(\n",
    "#     df.iterrows(),\n",
    "#     desc=\"Generating Descriptors\",\n",
    "#     total=df.index.shape[0],\n",
    "# ):\n",
    "#     filename = row[\"filename\"]\n",
    "#     bboxes = np.expand_dims(np.array((row[\"bbox.x1\"], row[\"bbox.y1\"], row[\"bbox.x2\"], row[\"bbox.y2\"]), dtype=\"float32\"), axis=0)\n",
    "#     result = submit_to_triton(filename, bboxes, request_id=filename)\n",
    "#     results.append(result.as_numpy(output_names[0]).reshape(-1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405994fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dlib.chinese_whispers_clustering(results, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a32ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f53e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = \"/data/photos/2013-grand-haven/grand-times-july-2013-little-nikon/102nikon/dscn1777.jpeg-1\"\n",
    "\n",
    "idx, _, filename = regex.split(\"(?r)(-+)\", samp, maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89101f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v, l in zip(ids, results, labels):\n",
    "    idx, _, filename = regex.split(\"(?r)(-+)\", k, maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in facedetect_data:\n",
    "    if items[\"faces\"][0][\"probability\"] == \"0\":\n",
    "        pass\n",
    "    else:\n",
    "        for k, v, l in zip(ids, results, labels):\n",
    "            idx, _, filename = regex.split(\"(?r)(-+)\", k, maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075c01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
