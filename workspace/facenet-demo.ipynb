{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from functools import singledispatch\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import tritonclient.grpc as grpcclient\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "if sys.version_info >= (3, 0):\n",
    "    import queue\n",
    "else:\n",
    "    import Queue as queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path: str):\n",
    "    \"\"\"\n",
    "    Loads an encoded image as an array of bytes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return np.expand_dims(np.fromfile(img_path, dtype=\"uint8\"), axis=0)\n",
    "\n",
    "\n",
    "def render_image(filename, image_wise_bboxes, outline_color=(118, 185, 0), linewidth=3):\n",
    "    \"\"\"Render images with overlain outputs.\"\"\"\n",
    "    image = Image.open(filename).convert(\"RGB\")\n",
    "    w, h = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    wpercent = 736 / float(image.size[0])\n",
    "    linewidth = int(linewidth / wpercent)\n",
    "    for box in image_wise_bboxes:\n",
    "        if (box[2] - box[0]) >= 0 and (box[3] - box[1]) >= 0:\n",
    "            draw.rectangle(box, outline=outline_color)\n",
    "            for i in range(linewidth):\n",
    "                x1 = max(0, box[0] - i)\n",
    "                y1 = max(0, box[1] - i)\n",
    "                x2 = min(w, box[2] + i)\n",
    "                y2 = min(h, box[3] + i)\n",
    "                draw.rectangle(box, outline=outline_color)\n",
    "    return image\n",
    "\n",
    "\n",
    "def submit_to_triton(image_data, input_name, output_names, request_id=None):\n",
    "    inputs = [grpcclient.InferInput(input_name, image_data.shape, \"UINT8\")]\n",
    "    inputs[0].set_data_from_numpy(image_data)\n",
    "\n",
    "    outputs = [\n",
    "        grpcclient.InferRequestedOutput(output_name, class_count=0)\n",
    "        for output_name in output_names\n",
    "    ]\n",
    "    return triton_client.infer(\n",
    "        model_name, inputs, outputs=outputs, request_id=request_id\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_model_grpc(model_metadata, model_config):\n",
    "    \"\"\"\n",
    "    Check the configuration of a model to make sure it meets the\n",
    "    requirements for an image classification network (as expected by\n",
    "    this client)\n",
    "    \"\"\"\n",
    "    if len(model_metadata.inputs) != 1:\n",
    "        raise Exception(\"expecting 1 input, got {}\".format(len(model_metadata.inputs)))\n",
    "\n",
    "    if len(model_config.input) != 1:\n",
    "        raise Exception(\n",
    "            \"expecting 1 input in model configuration, got {}\".format(\n",
    "                len(model_config.input)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    input_metadata = model_metadata.inputs[0]\n",
    "    output_metadata = model_metadata.outputs\n",
    "\n",
    "    return (input_metadata.name, output_metadata, model_config.max_batch_size)\n",
    "\n",
    "\n",
    "@singledispatch\n",
    "def to_serializable(val):\n",
    "    \"\"\"Used by default.\"\"\"\n",
    "    return str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "render = True\n",
    "n_processes = cpu_count()\n",
    "n_threads = (n_processes * 4) - 1\n",
    "model_name = \"facenet_ensemble\"\n",
    "model_version = \"1\"\n",
    "url = \"172.25.0.42:8001\"\n",
    "image_folder = \"/workspace/sample-imgs\"\n",
    "\n",
    "json_data_filename = \"/workspace/facedetect_data.json\"\n",
    "\n",
    "filenames = [\n",
    "    os.path.join(image_folder, f)\n",
    "    for f in os.listdir(image_folder)\n",
    "    if os.path.isfile(os.path.join(image_folder, f))\n",
    "] * n_threads\n",
    "\n",
    "triton_client = grpcclient.InferenceServerClient(url=url, verbose=False)\n",
    "\n",
    "model_metadata = triton_client.get_model_metadata(\n",
    "    model_name=model_name, model_version=model_version\n",
    ")\n",
    "\n",
    "model_config = triton_client.get_model_config(\n",
    "    model_name=model_name, model_version=model_version\n",
    ").config\n",
    "\n",
    "input_name, output_metadata, batch_size = parse_model_grpc(model_metadata, model_config)\n",
    "output_names = [i.name for i in output_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "with ProcessPoolExecutor(max_workers=n_threads) as executor:\n",
    "    p_images_data = [\n",
    "        p_image_data for p_image_data in executor.map(load_image, filenames)\n",
    "    ]\n",
    "\n",
    "process_pool_data = zip(p_images_data, filenames)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "    with tqdm(total=len(filenames)) as progress:\n",
    "        future_to_request = [\n",
    "            executor.submit(\n",
    "                submit_to_triton, t_image_data, input_name, output_names, t_request_id\n",
    "            )\n",
    "            for t_image_data, t_request_id in process_pool_data\n",
    "        ]\n",
    "\n",
    "        for future in as_completed(future_to_request):\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            infer_result = future.result()\n",
    "            this_id = infer_result.get_response().id\n",
    "            image_wise_bboxes = infer_result.as_numpy(output_names[0]).reshape(-1, 4)\n",
    "            image_probas = infer_result.as_numpy(output_names[1]).reshape(-1, 1)\n",
    "            results[this_id] = {output_names[0]: image_wise_bboxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94386624",
   "metadata": {},
   "outputs": [],
   "source": [
    "if render:\n",
    "    print(\"Rendering unique files in filenames...\")\n",
    "    rendered_images = []\n",
    "    img_w = 800\n",
    "    for this_id in results:\n",
    "        image_wise_bboxes = results[this_id][output_names[0]]\n",
    "        img = render_image(this_id, image_wise_bboxes)\n",
    "        wpercent = img_w / float(img.size[0])\n",
    "        hsize = int(float(img.size[1]) * float(wpercent))\n",
    "        img = img.resize((img_w, hsize), Image.ANTIALIAS)\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_file = {}\n",
    "\n",
    "for file in results:\n",
    "    face_list = []\n",
    "    for idx, bbox in enumerate(results[file][\"true_boxes\"]):\n",
    "        face_idx = \"face_{}\".format(idx)\n",
    "        face_list.append({face_idx: bbox})\n",
    "    json_data_file[file] = face_list\n",
    "\n",
    "with open(json_data_filename, \"w\") as outfile:\n",
    "    json.dump(json_data_file, outfile, default=to_serializable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591051fc",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
